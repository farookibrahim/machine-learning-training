{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "source": [
    "## Importing the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('train.csv')\n",
    "test_dataset = pd.read_csv('test.csv')"
   ]
  },
  {
   "source": [
    "## Concat both datasets and perform the data cleansing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = pd.concat([train_dataset, test_dataset], sort=False).reset_index(drop=True)\n",
    "all_dataset = all_dataset.drop([\"PassengerId\",\"Survived\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Pclass                                               Name     Sex   Age  \\\n",
       "0       3                            Braund, Mr. Owen Harris    male  22.0   \n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2       3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4       3                           Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1      1      0          PC 17599  71.2833   C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      1      0            113803  53.1000  C123        S  \n",
       "4      0      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "all_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age          263\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           1\n",
       "Cabin       1014\n",
       "Embarked       2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "all_dataset.isnull().sum()"
   ]
  },
  {
   "source": [
    "## Taking care of missing data & Encoding data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_name(x):\n",
    "\n",
    "    Title_Dictionary = {\n",
    "        \"Capt\": \"Officer\",\n",
    "        \"Col\": \"Officer\",\n",
    "        \"Major\": \"Officer\",\n",
    "        \"Jonkheer\": \"Royalty\",\n",
    "        \"Don\": \"Royalty\",\n",
    "        \"Dona\": \"Royalty\",\n",
    "        \"Sir\" : \"Royalty\",\n",
    "        \"Dr\": \"Officer\",\n",
    "        \"Rev\": \"Officer\",\n",
    "        \"the Countess\":\"Royalty\",\n",
    "        \"Mme\": \"Mrs\",\n",
    "        \"Mlle\": \"Miss\",\n",
    "        \"Ms\": \"Mrs\",\n",
    "        \"Mr\" : \"Mr\",\n",
    "        \"Mrs\" : \"Mrs\",\n",
    "        \"Miss\" : \"Miss\",\n",
    "        \"Master\" : \"Master\",\n",
    "        \"Lady\" : \"Royalty\"\n",
    "    }\n",
    "\n",
    "    # we extract the title from each name\n",
    "    x['Name'] = x['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "    # a map of more aggregated title\n",
    "    # we map each title\n",
    "    x['Name'] = x['Name'].map(Title_Dictionary)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex(x):\n",
    "    le = LabelEncoder()\n",
    "    x['Sex'] = le.fit_transform(x['Sex'])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_age(x):\n",
    "    # a function that fills the missing values of the Age variable\n",
    "    def fill_age(row):\n",
    "        grouped_train = x.iloc[:891].groupby(['Sex','Pclass','Name'])\n",
    "        grouped_median_train = grouped_train.median()\n",
    "        grouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Name', 'Age']]\n",
    "\n",
    "        condition = (\n",
    "            (grouped_median_train['Sex'] == row['Sex']) & \n",
    "            (grouped_median_train['Name'] == row['Name']) & \n",
    "            (grouped_median_train['Pclass'] == row['Pclass'])\n",
    "        )\n",
    "\n",
    "        return grouped_median_train[condition]['Age'].values[0]\n",
    "\n",
    "    x['Age'] = x.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ticket(x):\n",
    "    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
    "    def cleanTicket(ticket):\n",
    "        ticket = ticket.replace('.','')\n",
    "        ticket = ticket.replace('/','')\n",
    "        ticket = ticket.split()\n",
    "        ticket = map(lambda t : t.strip(), ticket)\n",
    "        ticket = list(filter(lambda t : not t.isdigit(), ticket))\n",
    "        if len(ticket) > 0:\n",
    "            return ticket[0]\n",
    "        else: \n",
    "            return 'XXX'\n",
    "\n",
    "    # Extracting dummy variables from tickets:\n",
    "    x['Ticket'] = list( map( cleanTicket, x['Ticket'] ) )\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fare(x):\n",
    "    # there's one missing fare value - replacing it with the mean.\n",
    "    x.Fare.fillna(x.iloc[:891].Fare.mean(), inplace=True)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cabin(x):\n",
    "    # replacing missing cabins with U (for Uknown)\n",
    "    x.Cabin.fillna('U', inplace=True)\n",
    "\n",
    "    # mapping each Cabin value with the cabin letter\n",
    "    x['Cabin'] = list( map( lambda c: c[0], x['Cabin'] ) )\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_embarked(x):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    x['Embarked'] = imp.fit_transform(x[['Embarked']])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_family(x):\n",
    "    # introducing a new feature : the size of families (including the passenger)\n",
    "    x['FamilySize'] = x['Parch'] + x['SibSp'] + 1\n",
    "\n",
    "    # introducing other features based on the family size\n",
    "    x['Singleton'] = x['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n",
    "    x['SmallFamily'] = x['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n",
    "    x['LargeFamily'] = x['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_pipe = Pipeline(steps=[\n",
    "    ('name', FunctionTransformer(process_name)),\n",
    "    ('sex', FunctionTransformer(process_sex)),\n",
    "    ('age', FunctionTransformer(process_age)),\n",
    "    ('ticket', FunctionTransformer(process_ticket)),\n",
    "    ('fare', FunctionTransformer(process_fare)),\n",
    "    ('cabin', FunctionTransformer(process_cabin)),\n",
    "    ('embarked', FunctionTransformer(process_embarked)),\n",
    "    ('family', FunctionTransformer(process_family)),\n",
    "])\n",
    "all_dataset = process_pipe.fit_transform(all_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Pclass  Name  Sex   Age  SibSp  Parch  Ticket     Fare Cabin Embarked  \\\n",
       "0       3    Mr    1  22.0      1      0      A5   7.2500     U        S   \n",
       "1       1   Mrs    0  38.0      1      0      PC  71.2833     C        C   \n",
       "2       3  Miss    0  26.0      0      0  STONO2   7.9250     U        S   \n",
       "3       1   Mrs    0  35.0      1      0     XXX  53.1000     C        S   \n",
       "4       3    Mr    1  35.0      0      0     XXX   8.0500     U        S   \n",
       "\n",
       "   FamilySize  Singleton  SmallFamily  LargeFamily  \n",
       "0           2          0            1            0  \n",
       "1           2          0            1            0  \n",
       "2           1          1            0            0  \n",
       "3           2          0            1            0  \n",
       "4           1          1            0            0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>FamilySize</th>\n      <th>Singleton</th>\n      <th>SmallFamily</th>\n      <th>LargeFamily</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A5</td>\n      <td>7.2500</td>\n      <td>U</td>\n      <td>S</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Mrs</td>\n      <td>0</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>C</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Miss</td>\n      <td>0</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STONO2</td>\n      <td>7.9250</td>\n      <td>U</td>\n      <td>S</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Mrs</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>XXX</td>\n      <td>53.1000</td>\n      <td>C</td>\n      <td>S</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>XXX</td>\n      <td>8.0500</td>\n      <td>U</td>\n      <td>S</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "all_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "FamilySize     0\n",
       "Singleton      0\n",
       "SmallFamily    0\n",
       "LargeFamily    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "all_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('ohe', OneHotEncoder(sparse=False), ['Pclass', 'Name', 'Ticket', 'Cabin', 'Embarked'])], remainder='passthrough')\n",
    "\n",
    "all_data = ct.fit_transform(all_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0. 0. 1. ... 0. 1. 0.]\n [1. 0. 0. ... 0. 1. 0.]\n [0. 0. 1. ... 1. 0. 0.]\n ...\n [0. 0. 1. ... 1. 0. 0.]\n [0. 0. 1. ... 1. 0. 0.]\n [0. 0. 1. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(all_data)"
   ]
  },
  {
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_train_test_target_data(x):\n",
    "    train_data, test_data = np.split(all_data, [891])\n",
    "    targets = train_dataset['Survived'].to_numpy()\n",
    "\n",
    "    return train_data, test_data, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, targets = recover_train_test_target_data(all_data)"
   ]
  },
  {
   "source": [
    "## Training the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(bootstrap=False, max_depth=3,\n",
       "                                        max_features='sqrt',\n",
       "                                        min_samples_split=5, n_jobs=-1,\n",
       "                                        random_state=2))])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(bootstrap = False, min_samples_leaf = 1, n_estimators = 100, min_samples_split = 5, max_features = 'sqrt', max_depth = 3, random_state = 2, n_jobs = -1)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "pipe.fit(train_data, targets)"
   ]
  },
  {
   "source": [
    "## Predicting the Test set results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipe.predict(test_data)"
   ]
  },
  {
   "source": [
    "## Save results to submission.csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "submission = pd.DataFrame( data={ 'PassengerId': test_dataset['PassengerId'], 'Survived': pred } )\n",
    "submission.to_csv('submission.csv', index=False, encoding='utf-8')\n",
    "submission.head()"
   ]
  },
  {
   "source": [
    "## Accuracy Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[96 14]\n [18 51]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8212290502793296"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, targets, test_size = 0.2, random_state = 0)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ]
}